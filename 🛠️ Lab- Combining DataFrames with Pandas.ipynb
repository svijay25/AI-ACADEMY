{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining DataFrames With Pandas - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll gain practice combining DataFrames through concatenation.  You'll also practice executing various types of joins to selectively combine the information stored in the tables.\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this lab you will:\n",
    "\n",
    "- Use concatenation to combine DataFrames  \n",
    "- Determine which type of join is preferred for two tables of data and a task  \n",
    "- Use different types of joins to merge dataframes\n",
    "\n",
    "\n",
    "## Concatenating DataFrames\n",
    "\n",
    "Run the cell below to create some sample DataFrames for us to work with.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame({'A': ['A0', 'A1', 'A2', 'A3'],\n",
    "                    'B': ['B0', 'B1', 'B2', 'B3'],\n",
    "                    'C': ['C0', 'C1', 'C2', 'C3'],\n",
    "                    'D': ['D0', 'D1', 'D2', 'D3']},\n",
    "                    index=[0, 1, 2, 3])\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame({'A': ['A4', 'A5', 'A6', 'A7'],\n",
    "                    'B': ['B4', 'B5', 'B6', 'B7'],\n",
    "                    'C': ['C4', 'C5', 'C6', 'C7'],\n",
    "                    'D': ['D4', 'D5', 'D6', 'D7']},\n",
    "                    index=[4, 5, 6, 7])\n",
    "\n",
    "df3 = pd.DataFrame({'A': ['A8', 'A9', 'A10', 'A11'],\n",
    "                    'B': ['B8', 'B9', 'B10', 'B11'],\n",
    "                    'C': ['C8', 'C9', 'C10', 'C11'], \n",
    "                    'D': ['D8', 'D9', 'D10', 'D11']},\n",
    "                    index=[8, 9, 10, 11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have multiple DataFrames to work with, you can execute a concatenation to join them together.  \n",
    "\n",
    "In the cell below, concatenate the 3 DataFrames together using the appropriate function.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame:\n",
      "      A    B    C    D\n",
      "0    A0   B0   C0   D0\n",
      "1    A1   B1   C1   D1\n",
      "2    A2   B2   C2   D2\n",
      "3    A3   B3   C3   D3\n",
      "4    A4   B4   C4   D4\n",
      "5    A5   B5   C5   D5\n",
      "6    A6   B6   C6   D6\n",
      "7    A7   B7   C7   D7\n",
      "8    A8   B8   C8   D8\n",
      "9    A9   B9   C9   D9\n",
      "10  A10  B10  C10  D10\n",
      "11  A11  B11  C11  D11\n"
     ]
    }
   ],
   "source": [
    "# Concatenate the DataFrames along the rows\n",
    "combined_df = pd.concat([df1, df2, df3])\n",
    "\n",
    "# Display the concatenated DataFrame\n",
    "print(\"Combined DataFrame:\")\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_EXPECTED OUTPUT:_**\n",
    "\n",
    "<img src=\"images/er1.png\">\n",
    "\n",
    "## Setting join conditions with concatenation\n",
    "\n",
    "You can also specify if the concatenation is an **_Outer Join_** or an **_Inner Join_**.  Next, you'll execute an inner join. Before you do, you need to create another table that contains some overlapping index values with a DataFrame that already exists. \n",
    "\n",
    "Run the cell below to create the new DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.DataFrame({'B': ['B2', 'B3', 'B6', 'B7'],\n",
    "                    'D': ['D2', 'D3', 'D6', 'D7'],\n",
    "                    'F': ['F2', 'F3', 'F6', 'F7']},\n",
    "                    index=[2, 3, 6, 7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, in the cell below, use the `pd.concat()` function to join DataFrames 1 and 4.  However, this time, specify that the `join` is `'inner'`, and `axis=1`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inner Join Concatenated DataFrame:\n",
      "    A   B   C   D   B   D   F\n",
      "2  A2  B2  C2  D2  B2  D2  F2\n",
      "3  A3  B3  C3  D3  B3  D3  F3\n"
     ]
    }
   ],
   "source": [
    "# Concatenate df1 and df4 using an inner join\n",
    "inner_join_df = pd.concat([df1, df4], axis=1, join='inner')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"\\nInner Join Concatenated DataFrame:\")\n",
    "print(inner_join_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_EXPECTED OUTPUT:_**\n",
    "\n",
    "<img src='images/er2.png'>\n",
    "\n",
    "You'll notice that in this case, the results contain only the rows with indexes that exist in both tables -- rows 2 and 3.  The resulting table contains the values for each column in both tables for the rows.  \n",
    "\n",
    "Note that there are many, many ways that you can make full use of the `pd.concat()` function in pandas to join DataFrames together -- these are just a few of the most common examples pulled from the pandas documentation on the subject. For a full view of all the ways you can use `pd.concat()`, see the [pandas documentation](http://pandas.pydata.org/pandas-docs/stable/merging.html).\n",
    "\n",
    "## Load data\n",
    "Now, it's time to move on to working with the Hearthstone cards database.  This database contains information on cards from the popular game, [Hearthstone](https://playhearthstone.com/en-us/). For full information on the dataset, see the [Kaggle page](https://www.kaggle.com/jeradrose/hearthstone-cards) for this dataset. \n",
    "\n",
    "This database consists of the following tables:\n",
    "\n",
    "* _cards_\n",
    "* *dust_costs*\n",
    "* _entourages_\n",
    "* _mechanics_\n",
    "* *play_requirements*\n",
    "\n",
    "Many of rows in each table -- but not all -- correspond to the same cards. As such, each table contains a column called `card_id` which acts as a **_Primary Key_** for each table.  You'll make use of these keys to **_join_** the different tables together into a single DataFrame. You'll also experiment with different types of joins to help us decide exactly what information you wish to combine.  \n",
    "\n",
    "Simply run the cell below to import the tables from the database as DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards_df = pd.read_csv('C:/Users/svijayaraghavan/Downloads/cards.csv')\n",
    "dust_df = pd.read_csv('C:/Users/svijayaraghavan/Downloads/dust.csv')\n",
    "entourages_df = pd.read_csv('C:/Users/svijayaraghavan/Downloads/entourages.csv')\n",
    "mechanics_df = pd.read_csv('C:/Users/svijayaraghavan/Downloads/mechanics.csv')\n",
    "play_requirements_df = pd.read_csv('C:/Users/svijayaraghavan/Downloads/play_requirements.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great.  Now, let's set the correct column, `card_id`, as the index column for each of these tables, and then display each to ensure that everything is as expected.  \n",
    "\n",
    "For each of the DataFrames you created in the cell above, call the `.set_index()` method and pass in `card_id`.  Also set `inplace=True`.  Then, display the `.head()` of each respective DataFrame to ensure everything worked.  \n",
    "\n",
    "**_NOTE:_** Since you are performing this operation in place, running any cell a second time will result in pandas throwing an error.  If you need to run something a second time, restart the kernel using the jupyter notebook menu at the top of the page.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inner Join between Cards and Dust Costs DataFrames:\n",
      "     card_id player_class    type                name  set  \\\n",
      "0  BRM_010t2        DRUID  MINION  Druid of the Flame  BRM   \n",
      "1  BRM_010t2        DRUID  MINION  Druid of the Flame  BRM   \n",
      "2  BRM_010t2        DRUID  MINION  Druid of the Flame  BRM   \n",
      "3  BRM_010t2        DRUID  MINION  Druid of the Flame  BRM   \n",
      "4     AT_132      NEUTRAL  MINION  Justicar Trueheart  TGT   \n",
      "\n",
      "                                                text  cost_x  attack  health  \\\n",
      "0                                                NaN     3.0     2.0     5.0   \n",
      "1                                                NaN     3.0     2.0     5.0   \n",
      "2                                                NaN     3.0     2.0     5.0   \n",
      "3                                                NaN     3.0     2.0     5.0   \n",
      "4  <b>Battlecry:</b> Replace your starting Hero P...     6.0     6.0     3.0   \n",
      "\n",
      "      rarity  collectible                                             flavor  \\\n",
      "0     COMMON          NaN                                                NaN   \n",
      "1     COMMON          NaN                                                NaN   \n",
      "2     COMMON          NaN                                                NaN   \n",
      "3     COMMON          NaN                                                NaN   \n",
      "4  LEGENDARY          1.0  It's like putting racing stripes and a giant s...   \n",
      "\n",
      "    race how_to_earn how_to_earn_golden targeting_arrow_text faction  \\\n",
      "0  BEAST         NaN                NaN                  NaN     NaN   \n",
      "1  BEAST         NaN                NaN                  NaN     NaN   \n",
      "2  BEAST         NaN                NaN                  NaN     NaN   \n",
      "3  BEAST         NaN                NaN                  NaN     NaN   \n",
      "4    NaN         NaN                NaN                  NaN     NaN   \n",
      "\n",
      "   durability             action  cost_y  \n",
      "0         NaN    CRAFTING_NORMAL      40  \n",
      "1         NaN    CRAFTING_GOLDEN     400  \n",
      "2         NaN  DISENCHANT_NORMAL       5  \n",
      "3         NaN  DISENCHANT_GOLDEN      50  \n",
      "4         NaN    CRAFTING_NORMAL    1600  \n"
     ]
    }
   ],
   "source": [
    "# Perform an inner join between cards_df and dust_df on card_id\n",
    "cards_dust_df = pd.merge(cards_df, dust_df, how='inner', on='card_id')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"\\nInner Join between Cards and Dust Costs DataFrames:\")\n",
    "print(cards_dust_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executing Joins\n",
    "\n",
    "Now that you have the tables loaded correctly, we're going to execute some joins. There are four different kinds of joins, which can best be visualized with Venn diagrams:\n",
    "\n",
    "<img src='images/Image_198_joins.png'>\n",
    "\n",
    "In these diagrams, each circle represents a DataFrame or SQL Table. The left table is the table you are working with, and the right table is the table you want to join to the table you are working with. You'll start by executing the most common type of join, an **_Inner Join_**.\n",
    "\n",
    "In the cell below, join `cards_df` with `mechanics_df` using the built-in `.join()` method on the `cards_df` object. \n",
    "\n",
    "Pass in the following parameters:\n",
    "* the table you want to join with, `mechanics_df`\n",
    "* The `how` parameter set to the type of join you want, `'inner'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index(['card_id'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m mechanics_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:/Users/svijayaraghavan/Downloads/mechanics.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Perform an inner join using the .join() method\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m cards_with_mechanics_df \u001b[38;5;241m=\u001b[39m cards_df\u001b[38;5;241m.\u001b[39mjoin(mechanics_df, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Set the 'card_id' column as the index for both DataFrames\u001b[39;00m\n\u001b[0;32m      9\u001b[0m cards_df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcard_id\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:10757\u001b[0m, in \u001b[0;36mDataFrame.join\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort, validate)\u001b[0m\n\u001b[0;32m  10747\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m how \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcross\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m  10748\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[0;32m  10749\u001b[0m             \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10750\u001b[0m             other,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10755\u001b[0m             validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m  10756\u001b[0m         )\n\u001b[1;32m> 10757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[0;32m  10758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10759\u001b[0m         other,\n\u001b[0;32m  10760\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mon,\n\u001b[0;32m  10761\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[0;32m  10762\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mon \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  10763\u001b[0m         right_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m  10764\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39m(lsuffix, rsuffix),\n\u001b[0;32m  10765\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[0;32m  10766\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m  10767\u001b[0m     )\n\u001b[0;32m  10768\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m  10769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m on \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:184\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[0;32m    171\u001b[0m         left_df,\n\u001b[0;32m    172\u001b[0m         right_df,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[0;32m    183\u001b[0m     )\n\u001b[1;32m--> 184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:888\u001b[0m, in \u001b[0;36m_MergeOperation.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m    884\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indicator_pre_merge(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright)\n\u001b[0;32m    886\u001b[0m join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m--> 888\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_and_concat(\n\u001b[0;32m    889\u001b[0m     join_index, left_indexer, right_indexer, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    890\u001b[0m )\n\u001b[0;32m    891\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_type)\n\u001b[0;32m    893\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindicator:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:840\u001b[0m, in \u001b[0;36m_MergeOperation._reindex_and_concat\u001b[1;34m(self, join_index, left_indexer, right_indexer, copy)\u001b[0m\n\u001b[0;32m    837\u001b[0m left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft[:]\n\u001b[0;32m    838\u001b[0m right \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright[:]\n\u001b[1;32m--> 840\u001b[0m llabels, rlabels \u001b[38;5;241m=\u001b[39m _items_overlap_with_suffix(\n\u001b[0;32m    841\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuffixes\n\u001b[0;32m    842\u001b[0m )\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m left_indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_range_indexer(left_indexer, \u001b[38;5;28mlen\u001b[39m(left)):\n\u001b[0;32m    845\u001b[0m     \u001b[38;5;66;03m# Pinning the index here (and in the right code just below) is not\u001b[39;00m\n\u001b[0;32m    846\u001b[0m     \u001b[38;5;66;03m#  necessary, but makes the `.take` more performant if we have e.g.\u001b[39;00m\n\u001b[0;32m    847\u001b[0m     \u001b[38;5;66;03m#  a MultiIndex for left.index.\u001b[39;00m\n\u001b[0;32m    848\u001b[0m     lmgr \u001b[38;5;241m=\u001b[39m left\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39mreindex_indexer(\n\u001b[0;32m    849\u001b[0m         join_index,\n\u001b[0;32m    850\u001b[0m         left_indexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    855\u001b[0m         use_na_proxy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    856\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2721\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[1;34m(left, right, suffixes)\u001b[0m\n\u001b[0;32m   2718\u001b[0m lsuffix, rsuffix \u001b[38;5;241m=\u001b[39m suffixes\n\u001b[0;32m   2720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lsuffix \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rsuffix:\n\u001b[1;32m-> 2721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns overlap but no suffix specified: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mto_rename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2723\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrenamer\u001b[39m(x, suffix: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2724\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   2725\u001b[0m \u001b[38;5;124;03m    Rename the left and right indices.\u001b[39;00m\n\u001b[0;32m   2726\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2737\u001b[0m \u001b[38;5;124;03m    x : renamed column name\u001b[39;00m\n\u001b[0;32m   2738\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: columns overlap but no suffix specified: Index(['card_id'], dtype='object')"
     ]
    }
   ],
   "source": [
    "# Load the data from CSV files\n",
    "cards_df = pd.read_csv('C:/Users/svijayaraghavan/Downloads/cards.csv')\n",
    "mechanics_df = pd.read_csv('C:/Users/svijayaraghavan/Downloads/mechanics.csv')\n",
    "\n",
    "# Perform an inner join using the .join() method\n",
    "cards_with_mechanics_df = cards_df.join(mechanics_df, how='inner')\n",
    "\n",
    "# Set the 'card_id' column as the index for both DataFrames\n",
    "cards_df.set_index('card_id', inplace=True)\n",
    "mechanics_df.set_index('card_id', inplace=True)\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"Cards with Mechanics DataFrame:\")\n",
    "print(cards_with_mechanics_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the output from the cell above and compare it to the original output of both the `cards_df` and `mechanics_df` DataFrame heads you displayed earlier.  Notice how this now combines the columns from both?\n",
    "\n",
    "**_Question_**\n",
    "\n",
    "If you inspect the original `cards_df` DataFrame, you'll notice that it contains  2,819 records.  The result of our inner join, `cards_with_mechanics_df`, contains only 1079 rows.  Why?\n",
    "\n",
    "Write your answer below this line:\n",
    "________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer; display: inline\">\n",
    "        <b><u>Solution (click to reveal)</u></b>\n",
    "    </summary>\n",
    "    <p>First we performed an inner join, which only includes records that are present in both tables. Although there were 2819 records in the left table, there were only 1079 records that existed in both tables, which are what you see in the resulting dataframe. </p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Types of Joins\n",
    "\n",
    "By default, the `.join()` method performs a left join if no parameter is passed in for `how=`.  In the cell below, perform a **_Left Join_** of `cards_with_mechanics_df` and `play_requirements_df`, with `cards_with_mechanics_df` as the left table.  \n",
    "\n",
    "Then, display `left_join_df` to inspect our results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left Join DataFrame:\n",
      "         player_class         type                name      set  \\\n",
      "card_id                                                           \n",
      "AT_132        NEUTRAL       MINION  Justicar Trueheart      TGT   \n",
      "GVG_011a      NEUTRAL  ENCHANTMENT          Shrink Ray      GVG   \n",
      "EX1_583       NEUTRAL       MINION  Priestess of Elune  EXPERT1   \n",
      "LOE_007t      WARLOCK        SPELL             Cursed!      LOE   \n",
      "LOE_007t      WARLOCK        SPELL             Cursed!      LOE   \n",
      "\n",
      "                                                       text  cost  attack  \\\n",
      "card_id                                                                     \n",
      "AT_132    <b>Battlecry:</b> Replace your starting Hero P...   6.0     6.0   \n",
      "GVG_011a                               -2 Attack this turn.   NaN     NaN   \n",
      "EX1_583    <b>Battlecry:</b> Restore 4 Health to your hero.   6.0     5.0   \n",
      "LOE_007t  While this is in your hand, take 2 damage at t...   2.0     NaN   \n",
      "LOE_007t  While this is in your hand, take 2 damage at t...   2.0     NaN   \n",
      "\n",
      "          health     rarity  collectible  \\\n",
      "card_id                                    \n",
      "AT_132       3.0  LEGENDARY          1.0   \n",
      "GVG_011a     NaN        NaN          NaN   \n",
      "EX1_583      4.0     COMMON          1.0   \n",
      "LOE_007t     NaN        NaN          NaN   \n",
      "LOE_007t     NaN        NaN          NaN   \n",
      "\n",
      "                                                     flavor race how_to_earn  \\\n",
      "card_id                                                                        \n",
      "AT_132    It's like putting racing stripes and a giant s...  NaN         NaN   \n",
      "GVG_011a                                                NaN  NaN         NaN   \n",
      "EX1_583   If she threatens to \"moon\" you, it's not what ...  NaN         NaN   \n",
      "LOE_007t                                                NaN  NaN         NaN   \n",
      "LOE_007t                                                NaN  NaN         NaN   \n",
      "\n",
      "         how_to_earn_golden targeting_arrow_text faction  durability  \\\n",
      "card_id                                                                \n",
      "AT_132                  NaN                  NaN     NaN         NaN   \n",
      "GVG_011a                NaN                  NaN     NaN         NaN   \n",
      "EX1_583                 NaN                  NaN     NaN         NaN   \n",
      "LOE_007t                NaN                  NaN     NaN         NaN   \n",
      "LOE_007t                NaN                  NaN     NaN         NaN   \n",
      "\n",
      "                     mechanic play_requirement  value  \n",
      "card_id                                                \n",
      "AT_132              BATTLECRY              NaN    NaN  \n",
      "GVG_011a  TAG_ONE_TURN_EFFECT              NaN    NaN  \n",
      "EX1_583             BATTLECRY              NaN    NaN  \n",
      "LOE_007t            EVIL_GLOW              NaN    NaN  \n",
      "LOE_007t   ImmuneToSpellpower              NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from CSV files\n",
    "cards_df = pd.read_csv('C:/Users/svijayaraghavan/Downloads/cards.csv')\n",
    "mechanics_df = pd.read_csv('C:/Users/svijayaraghavan/Downloads/mechanics.csv')\n",
    "play_requirements_df = pd.read_csv('C:/Users/svijayaraghavan/Downloads/play_requirements.csv')\n",
    "\n",
    "# Set the 'card_id' column as the index for the DataFrames\n",
    "cards_df.set_index('card_id', inplace=True)\n",
    "mechanics_df.set_index('card_id', inplace=True)\n",
    "play_requirements_df.set_index('card_id', inplace=True)\n",
    "\n",
    "# Perform an inner join between cards_df and mechanics_df\n",
    "cards_with_mechanics_df = cards_df.join(mechanics_df, how='inner')\n",
    "\n",
    "# Perform a left join between cards_with_mechanics_df and play_requirements_df\n",
    "left_join_df = cards_with_mechanics_df.join(play_requirements_df, how='left')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"Left Join DataFrame:\")\n",
    "print(left_join_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the results of this sort of join are dependent upon the position of each table--if you were to make `cards_with_mechanics_df` the right table and `play_requirements_df` the left table and then perform a **_Right Join_**, our results would be the same. \n",
    "\n",
    "**_Question:_**\n",
    "\n",
    "Describe what was included from each table in this join.\n",
    "\n",
    "Write your answer below this line:\n",
    "________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary style=\"cursor: pointer; display: inline\">\n",
    "        <b><u>Solution (click to reveal)</u></b>\n",
    "    </summary>\n",
    "    <p>Every record from cards_with_mechanics_df, as well as any records from play_requirements_df that have matching index values with a record from the left table. </p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outer Joins\n",
    "\n",
    "In the cell below, perform an outer join between `cards_df` and `dust_df`. Since these tables contain columns with the same name, we'll need to specify a suffix for at least one of them, so that the column can be renamed to avoid a naming collision. \n",
    "\n",
    "During this join, set the `rsuffix` parameter to `_dust`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the left join between cards_with_mechanics_df and play_requirements_df:\n",
    "\n",
    "From cards_with_mechanics_df (Left Table):\n",
    "\n",
    "All rows from cards_with_mechanics_df are included in the resulting DataFrame.\n",
    "This includes all columns from cards_df and mechanics_df that were combined in the previous inner join.\n",
    "From play_requirements_df (Right Table):\n",
    "\n",
    "Only the rows where the card_id matches with the card_id in cards_with_mechanics_df are included.\n",
    "Columns from play_requirements_df are added to the resulting DataFrame for these matching rows.\n",
    "For rows in cards_with_mechanics_df that do not have a corresponding card_id in play_requirements_df, the columns from play_requirements_df will have NaN values.\n",
    "Summary:\n",
    "The resulting DataFrame includes all rows from cards_with_mechanics_df.\n",
    "It includes the matching rows from play_requirements_df based on the card_id.\n",
    "Non-matching rows from play_requirements_df are not included.\n",
    "Columns from both DataFrames are present in the resulting DataFrame, with NaN values for non-matching entries from play_requirements_df.\n",
    "If the join were performed as a Right Join with play_requirements_df as the left table and cards_with_mechanics_df as the right table, the results would be the same due to the nature of right and left joins being symmetric in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outer Join DataFrame:\n",
      "        player_class   type    name  set  \\\n",
      "card_id                                    \n",
      "AT_001           NaN    NaN     NaN  NaN   \n",
      "AT_001           NaN    NaN     NaN  NaN   \n",
      "AT_002          MAGE  SPELL  Effigy  TGT   \n",
      "AT_004           NaN    NaN     NaN  NaN   \n",
      "AT_004           NaN    NaN     NaN  NaN   \n",
      "\n",
      "                                                      text  cost  attack  \\\n",
      "card_id                                                                    \n",
      "AT_001                                                 NaN   NaN     NaN   \n",
      "AT_001                                                 NaN   NaN     NaN   \n",
      "AT_002   <b>Secret:</b> When a friendly minion dies, su...   3.0     NaN   \n",
      "AT_004                                                 NaN   NaN     NaN   \n",
      "AT_004                                                 NaN   NaN     NaN   \n",
      "\n",
      "         health rarity  collectible              flavor race how_to_earn  \\\n",
      "card_id                                                                    \n",
      "AT_001      NaN    NaN          NaN                 NaN  NaN         NaN   \n",
      "AT_001      NaN    NaN          NaN                 NaN  NaN         NaN   \n",
      "AT_002      NaN   RARE          1.0  Burning man, brah.  NaN         NaN   \n",
      "AT_004      NaN    NaN          NaN                 NaN  NaN         NaN   \n",
      "AT_004      NaN    NaN          NaN                 NaN  NaN         NaN   \n",
      "\n",
      "        how_to_earn_golden targeting_arrow_text faction  durability mechanic  \\\n",
      "card_id                                                                        \n",
      "AT_001                 NaN                  NaN     NaN         NaN      NaN   \n",
      "AT_001                 NaN                  NaN     NaN         NaN      NaN   \n",
      "AT_002                 NaN                  NaN     NaN         NaN   SECRET   \n",
      "AT_004                 NaN                  NaN     NaN         NaN      NaN   \n",
      "AT_004                 NaN                  NaN     NaN         NaN      NaN   \n",
      "\n",
      "           play_requirement  value  \n",
      "card_id                             \n",
      "AT_001   REQ_TARGET_TO_PLAY    0.0  \n",
      "AT_001    REQ_MINION_TARGET    0.0  \n",
      "AT_002                  NaN    NaN  \n",
      "AT_004   REQ_TARGET_TO_PLAY    0.0  \n",
      "AT_004    REQ_MINION_TARGET    0.0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the data from CSV files\n",
    "cards_df = pd.read_csv('C:/Users/svijayaraghavan/Downloads/cards.csv')\n",
    "mechanics_df = pd.read_csv('C:/Users/svijayaraghavan/Downloads/mechanics.csv')\n",
    "play_requirements_df = pd.read_csv('C:/Users/svijayaraghavan/Downloads/play_requirements.csv')\n",
    "\n",
    "# Set the 'card_id' column as the index for the DataFrames\n",
    "cards_df.set_index('card_id', inplace=True)\n",
    "mechanics_df.set_index('card_id', inplace=True)\n",
    "play_requirements_df.set_index('card_id', inplace=True)\n",
    "\n",
    "# Perform an inner join between cards_df and mechanics_df\n",
    "cards_with_mechanics_df = cards_df.join(mechanics_df, how='inner')\n",
    "\n",
    "# Perform an outer join between cards_with_mechanics_df and play_requirements_df\n",
    "outer_join_df = cards_with_mechanics_df.join(play_requirements_df, how='outer')\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "print(\"Outer Join DataFrame:\")\n",
    "print(outer_join_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the output above.  Note that the naming collision has been avoided by renaming the `cost` column from the right table to `cost_dust`.  \n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lab, you learned how to:\n",
    "\n",
    "* Concatenate multiple DataFrames together into a single DataFrame\n",
    "* Understand and execute the various types of joins (inner, outer, left, and right joins)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
